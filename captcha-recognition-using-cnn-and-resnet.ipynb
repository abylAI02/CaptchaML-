{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2054411,"sourceType":"datasetVersion","datasetId":777753},{"sourceId":9511055,"sourceType":"datasetVersion","datasetId":5789389}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CAPTCHA Recognition Using Deep Learning\nThis notebook builds and trains a model to recognize text in CAPTCHA images. It uses datasets with labeled CAPTCHA images, preprocesses the data, and implements a ResNet-like architecture for training and evaluation.","metadata":{"id":"7VrdDYgnw5Pv"}},{"cell_type":"markdown","source":"## Importing Necessary Libraries","metadata":{"id":"5oNiC_-Nw5P1","jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom kagglehub import dataset_download\nfrom tqdm import tqdm\n\n# Set seeds for reproducibility\ntf.keras.utils.set_random_seed(42)\ntf.config.experimental.enable_op_determinism()","metadata":{"id":"o_50dceLw5P1","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:44:27.888384Z","iopub.execute_input":"2024-12-11T05:44:27.888789Z","iopub.status.idle":"2024-12-11T05:44:43.567041Z","shell.execute_reply.started":"2024-12-11T05:44:27.888753Z","shell.execute_reply":"2024-12-11T05:44:43.565568Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Configuration and Dataset Paths","metadata":{"id":"hFmzCHSKw5P2"}},{"cell_type":"code","source":"# Configuration\nIMAGE_HEIGHT = 50\nIMAGE_WIDTH = 100\nINITIAL_LEARNING_RATE = 1e-4\n\n# Dataset paths\ndataset1_path = dataset_download(\"tomtillo/5000-labelled-captcha-for-deeplearning\")\ndataset2_path = dataset_download(\"mrigaankjaswal/capcha-images-to-training-data\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-0ZiieKw5P3","outputId":"317d88aa-069f-4570-f90e-a6c63cca9534","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:44:43.569190Z","iopub.execute_input":"2024-12-11T05:44:43.569826Z","iopub.status.idle":"2024-12-11T05:47:35.097588Z","shell.execute_reply.started":"2024-12-11T05:44:43.569787Z","shell.execute_reply":"2024-12-11T05:47:35.096357Z"}},"outputs":[{"name":"stdout","text":"Mounting files to /kaggle/input/5000-labelled-captcha-for-deeplearning...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Load and Preprocess Dataset 1\n### Explanation\n1. Read images and labels from dataset.\n2. Resize images to a fixed size.\n3. Normalize pixel values to the range [0, 1].","metadata":{"id":"T4xuoaTsw5P3"}},{"cell_type":"code","source":"X1, y1 = [], []\nfor level in range(1, 6):\n    images = []\n    labels = []\n    image_folder = os.path.join(dataset1_path, f\"level_{level}\")\n    label_file = os.path.join(dataset1_path, f\"labels_level_{level}.csv\")\n\n    df = pd.read_csv(label_file, header=None, names=[\"filename\", \"label\"])\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        image_path = os.path.join(image_folder, row[\"filename\"])\n        if os.path.exists(image_path):\n            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n            images.append(img)\n            labels.append(str(row[\"label\"]))\n    X1.append(images)\n    y1.extend(labels)\n\nX1 = np.concatenate(X1, axis=0)\nX1 = X1 / 255.0\nX1 = X1.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AlnRhoIbw5P3","outputId":"115388cd-7a3d-4888-abf0-63060dcfb59d","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:47:35.099094Z","iopub.execute_input":"2024-12-11T05:47:35.099476Z","iopub.status.idle":"2024-12-11T05:51:43.936912Z","shell.execute_reply.started":"2024-12-11T05:47:35.099439Z","shell.execute_reply":"2024-12-11T05:51:43.935662Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 10001/10001 [00:49<00:00, 203.42it/s]\n100%|██████████| 10001/10001 [00:48<00:00, 208.09it/s]\n100%|██████████| 10001/10001 [00:50<00:00, 198.19it/s]\n100%|██████████| 10001/10001 [00:53<00:00, 187.35it/s]\n100%|██████████| 10001/10001 [00:46<00:00, 215.32it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Load and Preprocess Dataset 2","metadata":{"id":"1CcNp_FZw5P4"}},{"cell_type":"code","source":"X2, y2 = [], []\nfor filename in tqdm(os.listdir(dataset2_path)):\n    if filename.endswith(\".png\"):\n        image_path = os.path.join(dataset2_path, filename)\n        label = filename.split(\".png\")[0]\n        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n        X2.append(img)\n        y2.append(label)\n\nX2 = np.array(X2)\nX2 = X2 / 255.0\nX2 = X2.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XJJThKaw5P4","outputId":"cdf0fc27-77ea-4489-d963-d89eebdea2a0","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:51:43.938258Z","iopub.execute_input":"2024-12-11T05:51:43.938673Z","iopub.status.idle":"2024-12-11T05:51:43.950869Z","shell.execute_reply.started":"2024-12-11T05:51:43.938637Z","shell.execute_reply":"2024-12-11T05:51:43.949773Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Combine and Encode Datasets\n### Explanation\n1. Combine datasets.\n2. Encode labels as one-hot vectors.\n3. Pad labels to the maximum length.","metadata":{"id":"kvUbkSZfw5P4"}},{"cell_type":"code","source":"# Combine datasets\nX = np.concatenate((X1, X2), axis=0)\ny = np.concatenate((y1, y2), axis=0)\n\n# Character encoding\nchar_set = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\nchar_to_int = {char: idx for idx, char in enumerate(char_set)}\nint_to_char = {idx: char for char, idx in char_to_int.items()}\nnum_classes = len(char_set)\nmax_length = max(len(label) for label in y)\n\n# Encode labels\nencoded_labels = np.zeros((len(y), max_length, num_classes))\nfor i, label in enumerate(y):\n    for j, char in enumerate(label):\n        if j < max_length:\n            encoded_labels[i, j, char_to_int[char]] = 1","metadata":{"id":"nZbJOa-Vw5P4","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:51:43.953782Z","iopub.execute_input":"2024-12-11T05:51:43.954155Z","iopub.status.idle":"2024-12-11T05:51:45.167207Z","shell.execute_reply.started":"2024-12-11T05:51:43.954122Z","shell.execute_reply":"2024-12-11T05:51:45.166031Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Train-Test Split","metadata":{"id":"dXNj_xI3w5P5"}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, encoded_labels, test_size=0.2, random_state=42\n)","metadata":{"id":"xhq6-dmEw5P5","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:51:45.168512Z","iopub.execute_input":"2024-12-11T05:51:45.168881Z","iopub.status.idle":"2024-12-11T05:51:46.078442Z","shell.execute_reply.started":"2024-12-11T05:51:45.168845Z","shell.execute_reply":"2024-12-11T05:51:46.076883Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Define ResNet-like Model","metadata":{"id":"-b6YhiYmw5P5"}},{"cell_type":"code","source":"def residual_block(x, filters, kernel_size=3, downsample=False):\n    shortcut = x\n\n    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n\n    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = layers.BatchNormalization()(x)\n\n    if downsample:\n        shortcut = layers.Conv2D(filters, 1, strides=2, padding='same', kernel_regularizer=regularizers.l2(1e-4))(shortcut)\n        x = layers.MaxPooling2D(pool_size=2, strides=2, padding='same')(x)\n\n    if shortcut.shape[-1] != x.shape[-1]:\n        shortcut = layers.Conv2D(x.shape[-1], 1, padding='same', kernel_regularizer=regularizers.l2(1e-4))(shortcut)\n\n    x = layers.Add()([x, shortcut])\n    x = layers.Activation('relu')(x)\n    return x\n\ninputs = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1))\nx = layers.Conv2D(64, 7, strides=2, padding='same', kernel_regularizer=regularizers.l2(1e-4))(inputs)\nx = layers.BatchNormalization()(x)\nx = layers.Activation('relu')(x)\nx = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n\nx = residual_block(x, 64)\nx = residual_block(x, 128, downsample=True)\nx = residual_block(x, 256, downsample=True)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(max_length * num_classes, activation='softmax', kernel_regularizer=regularizers.l2(1e-4))(x)\nx = layers.Reshape((max_length, num_classes))(x)\n\nmodel = models.Model(inputs=inputs, outputs=x)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE, weight_decay=1e-5),\n              loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"mwQl5tH2w5P5","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:51:46.080120Z","iopub.execute_input":"2024-12-11T05:51:46.080598Z","iopub.status.idle":"2024-12-11T05:51:46.376843Z","shell.execute_reply.started":"2024-12-11T05:51:46.080560Z","shell.execute_reply":"2024-12-11T05:51:46.375410Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Train the Model with Callbacks","metadata":{"id":"-b4-x-mhw5P5"}},{"cell_type":"code","source":"%%time\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy')\n]\n\nhistory = model.fit(\n    datagen.flow(X_train, y_train, batch_size=64),\n    epochs=200,\n    validation_data=(X_test, y_test),\n    callbacks=callbacks,\n    steps_per_epoch=len(X_train) // 64\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETZ8GLDxw5P6","outputId":"4056e358-6be3-453c-f818-ad562d10d689","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:51:46.378550Z","iopub.execute_input":"2024-12-11T05:51:46.378920Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 988ms/step - accuracy: 0.1024 - loss: 2.8715 - val_accuracy: 0.1048 - val_loss: 2.5796 - learning_rate: 1.0000e-04\nEpoch 2/200\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.1048 - val_loss: 2.5796 - learning_rate: 1.0000e-04\nEpoch 3/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 979ms/step - accuracy: 0.1545 - loss: 2.4057 - val_accuracy: 0.1245 - val_loss: 2.7420 - learning_rate: 1.0000e-04\nEpoch 4/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.1245 - val_loss: 2.7420 - learning_rate: 1.0000e-04\nEpoch 5/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 987ms/step - accuracy: 0.2404 - loss: 2.2321 - val_accuracy: 0.3435 - val_loss: 1.9591 - learning_rate: 1.0000e-04\nEpoch 6/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3435 - val_loss: 1.9591 - learning_rate: 1.0000e-04\nEpoch 7/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 992ms/step - accuracy: 0.3143 - loss: 2.0372 - val_accuracy: 0.2032 - val_loss: 2.6679 - learning_rate: 1.0000e-04\nEpoch 8/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2032 - val_loss: 2.6679 - learning_rate: 1.0000e-04\nEpoch 9/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 1s/step - accuracy: 0.3748 - loss: 1.8651 - val_accuracy: 0.3857 - val_loss: 1.8786 - learning_rate: 1.0000e-04\nEpoch 10/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3857 - val_loss: 1.8786 - learning_rate: 1.0000e-04\nEpoch 11/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 999ms/step - accuracy: 0.4220 - loss: 1.7238 - val_accuracy: 0.4656 - val_loss: 1.5703 - learning_rate: 1.0000e-04\nEpoch 12/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4656 - val_loss: 1.5703 - learning_rate: 1.0000e-04\nEpoch 13/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 999ms/step - accuracy: 0.4622 - loss: 1.6018 - val_accuracy: 0.5376 - val_loss: 1.3736 - learning_rate: 1.0000e-04\nEpoch 14/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5376 - val_loss: 1.3736 - learning_rate: 1.0000e-04\nEpoch 15/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 1s/step - accuracy: 0.5055 - loss: 1.4849 - val_accuracy: 0.5286 - val_loss: 1.4415 - learning_rate: 1.0000e-04\nEpoch 16/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 55ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5286 - val_loss: 1.4415 - learning_rate: 1.0000e-04\nEpoch 17/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 1s/step - accuracy: 0.5497 - loss: 1.3729 - val_accuracy: 0.6717 - val_loss: 1.0069 - learning_rate: 1.0000e-04\nEpoch 18/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6717 - val_loss: 1.0069 - learning_rate: 1.0000e-04\nEpoch 19/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 1s/step - accuracy: 0.5889 - loss: 1.2678 - val_accuracy: 0.6376 - val_loss: 1.0863 - learning_rate: 1.0000e-04\nEpoch 20/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6376 - val_loss: 1.0863 - learning_rate: 1.0000e-04\nEpoch 21/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 991ms/step - accuracy: 0.6257 - loss: 1.1761 - val_accuracy: 0.7168 - val_loss: 0.9290 - learning_rate: 1.0000e-04\nEpoch 22/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7168 - val_loss: 0.9290 - learning_rate: 1.0000e-04\nEpoch 23/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 1s/step - accuracy: 0.6582 - loss: 1.0965 - val_accuracy: 0.6041 - val_loss: 1.2488 - learning_rate: 1.0000e-04\nEpoch 24/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 55ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6041 - val_loss: 1.2488 - learning_rate: 1.0000e-04\nEpoch 25/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 1s/step - accuracy: 0.6876 - loss: 1.0234 - val_accuracy: 0.7979 - val_loss: 0.7008 - learning_rate: 1.0000e-04\nEpoch 26/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7979 - val_loss: 0.7008 - learning_rate: 1.0000e-04\nEpoch 27/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 995ms/step - accuracy: 0.7173 - loss: 0.9566 - val_accuracy: 0.7943 - val_loss: 0.7321 - learning_rate: 1.0000e-04\nEpoch 28/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 55ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7943 - val_loss: 0.7321 - learning_rate: 1.0000e-04\nEpoch 29/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 1s/step - accuracy: 0.7382 - loss: 0.8949 - val_accuracy: 0.8163 - val_loss: 0.6700 - learning_rate: 1.0000e-04\nEpoch 30/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8163 - val_loss: 0.6700 - learning_rate: 1.0000e-04\nEpoch 31/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 1s/step - accuracy: 0.7555 - loss: 0.8504 - val_accuracy: 0.8375 - val_loss: 0.5794 - learning_rate: 1.0000e-04\nEpoch 32/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8375 - val_loss: 0.5794 - learning_rate: 1.0000e-04\nEpoch 33/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 1s/step - accuracy: 0.7729 - loss: 0.8065 - val_accuracy: 0.7841 - val_loss: 0.7358 - learning_rate: 1.0000e-04\nEpoch 34/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7841 - val_loss: 0.7358 - learning_rate: 1.0000e-04\nEpoch 35/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 1s/step - accuracy: 0.7884 - loss: 0.7724 - val_accuracy: 0.8950 - val_loss: 0.4570 - learning_rate: 1.0000e-04\nEpoch 36/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8950 - val_loss: 0.4570 - learning_rate: 1.0000e-04\nEpoch 37/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 1s/step - accuracy: 0.8041 - loss: 0.7284 - val_accuracy: 0.8931 - val_loss: 0.4596 - learning_rate: 1.0000e-04\nEpoch 38/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8931 - val_loss: 0.4596 - learning_rate: 1.0000e-04\nEpoch 39/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 1s/step - accuracy: 0.8136 - loss: 0.7016 - val_accuracy: 0.8807 - val_loss: 0.5005 - learning_rate: 1.0000e-04\nEpoch 40/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8807 - val_loss: 0.5005 - learning_rate: 1.0000e-04\nEpoch 41/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 1s/step - accuracy: 0.8271 - loss: 0.6613 - val_accuracy: 0.8438 - val_loss: 0.5904 - learning_rate: 5.0000e-05\nEpoch 42/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8438 - val_loss: 0.5904 - learning_rate: 5.0000e-05\nEpoch 43/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 1s/step - accuracy: 0.8356 - loss: 0.6367 - val_accuracy: 0.7267 - val_loss: 0.9923 - learning_rate: 5.0000e-05\nEpoch 44/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7267 - val_loss: 0.9923 - learning_rate: 5.0000e-05\nEpoch 45/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 1s/step - accuracy: 0.8424 - loss: 0.6219 - val_accuracy: 0.9485 - val_loss: 0.2854 - learning_rate: 5.0000e-05\nEpoch 46/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9485 - val_loss: 0.2854 - learning_rate: 5.0000e-05\nEpoch 47/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 1s/step - accuracy: 0.8480 - loss: 0.6091 - val_accuracy: 0.9573 - val_loss: 0.2709 - learning_rate: 5.0000e-05\nEpoch 48/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9573 - val_loss: 0.2709 - learning_rate: 5.0000e-05\nEpoch 49/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 1s/step - accuracy: 0.8528 - loss: 0.5893 - val_accuracy: 0.9350 - val_loss: 0.3367 - learning_rate: 5.0000e-05\nEpoch 50/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9350 - val_loss: 0.3367 - learning_rate: 5.0000e-05\nEpoch 51/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 1s/step - accuracy: 0.8546 - loss: 0.5857 - val_accuracy: 0.6356 - val_loss: 1.3258 - learning_rate: 5.0000e-05\nEpoch 52/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6356 - val_loss: 1.3258 - learning_rate: 5.0000e-05\nEpoch 53/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 1s/step - accuracy: 0.8617 - loss: 0.5642 - val_accuracy: 0.9532 - val_loss: 0.2765 - learning_rate: 2.5000e-05\nEpoch 54/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 55ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9532 - val_loss: 0.2765 - learning_rate: 2.5000e-05\nEpoch 55/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 1s/step - accuracy: 0.8619 - loss: 0.5632 - val_accuracy: 0.9658 - val_loss: 0.2404 - learning_rate: 2.5000e-05\nEpoch 56/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9658 - val_loss: 0.2404 - learning_rate: 2.5000e-05\nEpoch 57/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 1s/step - accuracy: 0.8662 - loss: 0.5537 - val_accuracy: 0.9661 - val_loss: 0.2368 - learning_rate: 2.5000e-05\nEpoch 58/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9661 - val_loss: 0.2368 - learning_rate: 2.5000e-05\nEpoch 59/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 1s/step - accuracy: 0.8666 - loss: 0.5475 - val_accuracy: 0.9694 - val_loss: 0.2273 - learning_rate: 2.5000e-05\nEpoch 60/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9694 - val_loss: 0.2273 - learning_rate: 2.5000e-05\nEpoch 61/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 1s/step - accuracy: 0.8687 - loss: 0.5439 - val_accuracy: 0.9706 - val_loss: 0.2243 - learning_rate: 2.5000e-05\nEpoch 62/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9706 - val_loss: 0.2243 - learning_rate: 2.5000e-05\nEpoch 63/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 1s/step - accuracy: 0.8731 - loss: 0.5306 - val_accuracy: 0.9625 - val_loss: 0.2424 - learning_rate: 2.5000e-05\nEpoch 64/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 56ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9625 - val_loss: 0.2424 - learning_rate: 2.5000e-05\nEpoch 65/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 1s/step - accuracy: 0.8712 - loss: 0.5314 - val_accuracy: 0.9333 - val_loss: 0.3259 - learning_rate: 2.5000e-05\nEpoch 66/200\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 55ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9333 - val_loss: 0.3259 - learning_rate: 2.5000e-05\nEpoch 67/200\n\u001b[1m347/625\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 965ms/step - accuracy: 0.8731 - loss: 0.5265","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate the Model","metadata":{"id":"S4MybUWmw5P6"}},{"cell_type":"code","source":"def decode_predictions(predictions):\n    decoded_labels = []\n    for prediction in predictions:\n        decoded_label = ''.join([int_to_char[np.argmax(char_probs)] for char_probs in prediction])\n        decoded_labels.append(decoded_label)\n    return decoded_labels\n\n# Predictions\ny_pred_probs = model.predict(X_test)\ny_test_decoded = decode_predictions(y_test)\ny_pred_decoded = decode_predictions(y_pred_probs)\n\n# Metrics\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test_decoded, y_pred_decoded))\naccuracy = accuracy_score(y_test_decoded, y_pred_decoded)\nprint(f\"\\nOverall Accuracy: {accuracy*100:.2f}%\")","metadata":{"id":"yeVgAnS0w5P6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom tensorflow.keras.models import Model","metadata":{"id":"mUkql6d3HhEW","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Display Preprocessed CAPTCHA Samples\n# Purpose: Visualize preprocessed CAPTCHA samples to ensure correct resizing and normalization.\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\naxes = axes.ravel()\n\nfor i in range(10):\n    idx = random.randint(0, len(X_train) - 1)\n    axes[i].imshow(X_train[idx].squeeze(), cmap='gray')\n    axes[i].set_title(f\"Label: {decode_predictions([y_train[idx]])[0]}\")\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"R7v49yZFHjU-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Label Length Distribution\n# Purpose: Understand the distribution of label lengths in the dataset to verify padding requirements.\nlabel_lengths = [len(label) for label in y]\nplt.figure(figsize=(10, 6))\nplt.hist(label_lengths, bins=range(1, max_length + 2), edgecolor='black', alpha=0.75)\nplt.title('Distribution of CAPTCHA Label Lengths')\nplt.xlabel('Label Length')\nplt.ylabel('Frequency')\nplt.grid(axis='y')\nplt.show()","metadata":{"id":"A_Vs2o_THkrF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Training History\n# Purpose: Monitor the training and validation accuracy/loss over epochs to evaluate performance.\nplt.figure(figsize=(14, 6))","metadata":{"id":"Rg0HhC_3HmEV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\nplt.title('Model Accuracy Over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid()\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss', marker='o')\nplt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\nplt.title('Model Loss Over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"646SGcZKHncD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Model Predictions vs Ground Truth\n# Purpose: Compare model predictions with ground truth to identify common errors and performance visually.\nfig, axes = plt.subplots(3, 5, figsize=(15, 10))\naxes = axes.ravel()\n\nfor i in range(15):\n    idx = random.randint(0, len(X_test) - 1)\n    axes[i].imshow(X_test[idx].squeeze(), cmap='gray')\n    true_label = decode_predictions([y_test[idx]])[0]\n    pred_label = decode_predictions([y_pred_probs[idx]])[0]\n    axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\", fontsize=10)\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"C-a0k2YjHrsV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Confusion Matrix for First Characters\n# Purpose: Identify confusion patterns in the first character of predictions.\ntrue_first_chars = [label[0] for label in decode_predictions(y_test)]\npred_first_chars = [label[0] for label in decode_predictions(y_pred_probs)]\n\nconf_matrix = confusion_matrix(true_first_chars, pred_first_chars, labels=list(char_set))\nplt.figure(figsize=(12, 10))\ndisp = ConfusionMatrixDisplay(conf_matrix, display_labels=list(char_set))\ndisp.plot(cmap='viridis', xticks_rotation='vertical', values_format='.0f')\nplt.title('Confusion Matrix for First Character Predictions')\nplt.show()","metadata":{"id":"fR3uXDpAHtBT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Activation Map Visualization\n# Purpose: Visualize intermediate activation maps to understand what the model learns.\nimage_idx = random.randint(0, len(X_test) - 1)\ntest_image = X_test[image_idx:image_idx+1]\n\n# Extracting outputs of convolutional layers\nlayer_outputs = [layer.output for layer in model.layers if 'conv2d' in layer.name]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(test_image)\n\n# Plot activations of the first convolutional layer\nlayer_names = [layer.name for layer in model.layers if 'conv2d' in layer.name]\nfirst_layer_activations = activations[0]\n\nfig, axes = plt.subplots(4, 8, figsize=(15, 8))\naxes = axes.ravel()\n\nfor i in range(32):  # Visualize first 32 filters\n    axes[i].imshow(first_layer_activations[0, :, :, i], cmap='viridis')\n    axes[i].axis('off')\n\nplt.suptitle(f\"Activation Maps of Layer: {layer_names[0]}\")\nplt.tight_layout()\nplt.show()","metadata":{"id":"WEsP3QB3Hdy3","trusted":true},"outputs":[],"execution_count":null}]}